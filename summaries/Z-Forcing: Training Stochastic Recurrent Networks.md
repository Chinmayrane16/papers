##### [20-01-10] [paper77]
- Z-Forcing: Training Stochastic Recurrent Networks [[pdf]](https://arxiv.org/abs/1711.05411) [[code]](https://github.com/sordonia/zforcing) [[pdf with comments]](https://github.com/fregu856/papers/blob/master/commented_pdfs/Z-Forcing:%20Training%20Stochastic%20Recurrent%20Networks.pdf) [[comments]](https://github.com/fregu856/papers/blob/master/summaries/Z-Forcing:%20Training%20Stochastic%20Recurrent%20Networks.md)
- *Anirudh Goyal, Alessandro Sordoni, Marc-Alexandre Côté, Nan Rosemary Ke, Yoshua Bengio*
- `2017-11-15, NeurIPS 2017`

****

### General comments on paper quality:
- Quite interesting and well-written paper.

### Comments:
- Seems like Marco Fraccaro's [thesis](https://github.com/fregu856/papers/blob/master/summaries/Deep%20Latent%20Variable%20Models%20for%20Sequential%20Data.md) covers most of this paper, overall the proposed architecture is still quite similar to VRNN/SRNN both in design and performance.

- The auxiliary cost seems to improve performance quite consistently, but nothing revolutionary.  

- It is not quite clear to me if the proposed architecture is more or less difficult / computationally expensive to train than SRNN.
